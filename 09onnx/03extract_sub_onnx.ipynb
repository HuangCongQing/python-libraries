{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.yuque.com/huangzhongqing/pytorch/ucvem31c9nimql9m#hkKRJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试：生成一个卷积模型导出onnx\n",
    "\n",
    "![](https://pic1.zhimg.com/80/v2-8298194c4614a98d6cf5868e3e34eccc_720w.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    " \n",
    "class Model(torch.nn.Module): \n",
    " \n",
    "    def __init__(self): \n",
    "        super().__init__() \n",
    "        self.convs1 = torch.nn.Sequential(torch.nn.Conv2d(3, 3, 3), \n",
    "                                          torch.nn.Conv2d(3, 3, 3), \n",
    "                                          torch.nn.Conv2d(3, 3, 3)) \n",
    "        self.convs2 = torch.nn.Sequential(torch.nn.Conv2d(3, 3, 3), \n",
    "                                          torch.nn.Conv2d(3, 3, 3)) \n",
    "        self.convs3 = torch.nn.Sequential(torch.nn.Conv2d(3, 3, 3), \n",
    "                                          torch.nn.Conv2d(3, 3, 3)) \n",
    "        self.convs4 = torch.nn.Sequential(torch.nn.Conv2d(3, 3, 3), \n",
    "                                          torch.nn.Conv2d(3, 3, 3), \n",
    "                                          torch.nn.Conv2d(3, 3, 3)) \n",
    "    def forward(self, x): \n",
    "        x = self.convs1(x) \n",
    "        x1 = self.convs2(x) \n",
    "        x2 = self.convs3(x) \n",
    "        x = x1 + x2 \n",
    "        x = self.convs4(x) \n",
    "        return x \n",
    " \n",
    "model = Model() \n",
    "input = torch.randn(1, 3, 20, 20) \n",
    " \n",
    "torch.onnx.export(model, input, 'whole_model.onnx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取子模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx  \n",
    " \n",
    "onnx.utils.extract_model('whole_model.onnx', 'partial_model.onnx', ['22'], ['28']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加额外输出\n",
    "\n",
    "我们在提取时新设定了一个输出张量，如下面的代码所示：\n",
    "\n",
    "`onnx.utils.extract_model('whole_model.onnx', 'submodel_1.onnx', ['22'], ['27', '31']) `\n",
    "我们可以看到子模型会添加一条把张量输出的新边，如下图所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.utils.extract_model('whole_model.onnx', 'submodel_1.onnx', ['22'], ['27', '31']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加冗余输入\n",
    "\n",
    "如果我们还是像开始一样提取边 22 到边 28 之间的子模型，但是多添加了一个输入 input.1，那么提取出的子模型会有一个冗余的输入 input.1，如下面的代码所示：\n",
    "\n",
    "`onnx.utils.extract_model('whole_model.onnx', 'submodel_2.onnx', ['22', 'input.1'], ['28']) `\n",
    "从下图可以看到：无论给这个输入传入什么值，都不会影响子模型的输出。可以认为如果只用子模型的部分输入就能得到输出，那么那些”较早“的多出来的输入就是冗余的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.utils.extract_model('whole_model.onnx', 'submodel_2.onnx', ['22', 'input.1'], ['28']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入信息不足(报错)\n",
    "\n",
    "这次，我们尝试提取的子模型输入是边 24，输出是边 28。如下面的代码和图所示：\n",
    "\n",
    "从图中可以看出，想通过边 24 计算边 28 的结果，至少还需要输入边 26，或者更上面的边。仅凭借边 24 是无法计算出边 28 的结果的，因此这样提取子模型会报错。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "Nodes in a graph must be topologically sorted, however input 'input.1' of node: \nname: Conv_0 OpType: Conv\n is not output of any previous nodes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/chongqinghuang/code/python-libraries/09onnx/03extract_sub_onnx.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chongqinghuang/code/python-libraries/09onnx/03extract_sub_onnx.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Error \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chongqinghuang/code/python-libraries/09onnx/03extract_sub_onnx.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m onnx\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mextract_model(\u001b[39m'\u001b[39;49m\u001b[39mwhole_model.onnx\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msubmodel_3.onnx\u001b[39;49m\u001b[39m'\u001b[39;49m, [\u001b[39m'\u001b[39;49m\u001b[39m24\u001b[39;49m\u001b[39m'\u001b[39;49m], [\u001b[39m'\u001b[39;49m\u001b[39m28\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/anaconda3/envs/waymo_38/lib/python3.8/site-packages/onnx/utils.py:196\u001b[0m, in \u001b[0;36mextract_model\u001b[0;34m(input_path, output_path, input_names, output_names, check_model)\u001b[0m\n\u001b[1;32m    194\u001b[0m onnx\u001b[39m.\u001b[39msave(extracted, output_path)\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m check_model:\n\u001b[0;32m--> 196\u001b[0m     onnx\u001b[39m.\u001b[39;49mchecker\u001b[39m.\u001b[39;49mcheck_model(output_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/waymo_38/lib/python3.8/site-packages/onnx/checker.py:97\u001b[0m, in \u001b[0;36mcheck_model\u001b[0;34m(model, full_check)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m# If model is a path instead of ModelProto\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 97\u001b[0m     C\u001b[39m.\u001b[39;49mcheck_model_path(model)\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m full_check:\n\u001b[1;32m     99\u001b[0m         onnx\u001b[39m.\u001b[39mshape_inference\u001b[39m.\u001b[39minfer_shapes_path(model, check_type\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, strict_mode\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValidationError\u001b[0m: Nodes in a graph must be topologically sorted, however input 'input.1' of node: \nname: Conv_0 OpType: Conv\n is not output of any previous nodes."
     ]
    }
   ],
   "source": [
    "# Error \n",
    "onnx.utils.extract_model('whole_model.onnx', 'submodel_3.onnx', ['24'], ['28']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('waymo_38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44c80fdca727e273b3b1fdcfb86e5664b0451e88fa74e3d1ad2cb050c7994d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
